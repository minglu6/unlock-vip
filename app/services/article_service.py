import os
import re
import requests
import json
import logging
from datetime import datetime
from bs4 import BeautifulSoup
from .auth_service import AuthService
from app.core.config import settings

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

class ArticleService:
    """æ–‡ç« ä¸‹è½½æœåŠ¡ - ä½¿ç”¨requestsè·å–æ–‡ç« å†…å®¹"""

    def __init__(self):
        # å¯ç”¨éªŒè¯ç è‡ªåŠ¨è¯†åˆ«æœåŠ¡
        self.auth_service = AuthService(use_captcha_service=True, debug=False)
        self.is_logged_in = False

    def ensure_login(self):
        """ç¡®ä¿å·²ç™»å½•"""
        if self.is_logged_in:
            return

        # å°è¯•åŠ è½½cookies
        cookies_loaded = self.auth_service.load_cookies()

        if not cookies_loaded:
            # æ²¡æœ‰cookies,æ‰§è¡Œç™»å½•
            username = settings.CSDN_USERNAME
            password = settings.CSDN_PASSWORD

            if not username or not password:
                raise Exception("CSDNç™»å½•å‡­è¯æœªé…ç½®,è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®CSDN_USERNAMEå’ŒCSDN_PASSWORD")

            login_success = self.auth_service.login(username, password)
            if not login_success:
                raise Exception("CSDNç™»å½•å¤±è´¥,è¯·æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç ")

        # éªŒè¯ç™»å½•çŠ¶æ€
        if not self.auth_service.verify_login():
            # cookieså¤±æ•ˆï¼Œé‡æ–°ç™»å½•
            username = settings.CSDN_USERNAME
            password = settings.CSDN_PASSWORD

            if not username or not password:
                raise Exception("CSDNç™»å½•å‡­è¯æœªé…ç½®")

            login_success = self.auth_service.login(username, password)
            if not login_success:
                raise Exception("CSDNç™»å½•å¤±è´¥")

        self.is_logged_in = True

    def _force_relogin(self) -> bool:
        """
        å¼ºåˆ¶é‡æ–°ç™»å½•ï¼Œè·å–æ–°çš„æœ‰æ•ˆcookies

        Returns:
            bool: é‡æ–°ç™»å½•æ˜¯å¦æˆåŠŸ
        """
        logger.info("ğŸ”„ å¼€å§‹å¼ºåˆ¶é‡æ–°ç™»å½•æµç¨‹...")

        try:
            # æ¸…é™¤å½“å‰çš„ç™»å½•çŠ¶æ€
            self.is_logged_in = False

            # æ¸…é™¤ç°æœ‰çš„cookies
            if self.auth_service:
                self.auth_service.cookies.clear()

            # é‡æ–°æ‰§è¡Œå®Œæ•´çš„ç™»å½•æµç¨‹
            username = settings.CSDN_USERNAME
            password = settings.CSDN_PASSWORD

            if not username or not password:
                logger.error("âŒ CSDNç™»å½•å‡­è¯æœªé…ç½®ï¼Œæ— æ³•é‡æ–°ç™»å½•")
                return False

            logger.info(f"ğŸ“ ä½¿ç”¨ç”¨æˆ·å {username} é‡æ–°ç™»å½•...")

            # æ‰§è¡Œç™»å½•
            login_success = self.auth_service.login(username, password)

            if login_success:
                logger.info("âœ… é‡æ–°ç™»å½•æˆåŠŸ")

                # éªŒè¯æ–°çš„ç™»å½•çŠ¶æ€
                if self.auth_service.verify_login():
                    logger.info("âœ… æ–°çš„ç™»å½•çŠ¶æ€éªŒè¯é€šè¿‡")
                    self.is_logged_in = True
                    return True
                else:
                    logger.warning("âš ï¸  æ–°çš„ç™»å½•çŠ¶æ€éªŒè¯å¤±è´¥ï¼Œä½†ç™»å½•è¿‡ç¨‹æˆåŠŸ")
                    self.is_logged_in = True
                    return True
            else:
                logger.error("âŒ é‡æ–°ç™»å½•å¤±è´¥")
                return False

        except Exception as e:
            logger.error(f"âŒ é‡æ–°ç™»å½•è¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            return False

    def extract_article_id(self, url: str) -> str:
        """
        ä»æ–‡ç« URLä¸­æå–æ–‡ç« ID

        Args:
            url: æ–‡ç« URLï¼Œä¾‹å¦‚ https://blog.csdn.net/username/article/details/151638092

        Returns:
            str: æ–‡ç« ID
        """
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ–‡ç« ID
        match = re.search(r'/article/details/(\d+)', url)
        if match:
            return match.group(1)

        # æ£€æŸ¥æ˜¯å¦æ˜¯wenku.csdn.netçš„URL
        if 'wenku.csdn.net' in url:
            # æå–wenkuæ–‡æ¡£IDï¼Œæ”¯æŒå¤šç§æ ¼å¼
            wenku_match = re.search(r'wenku\.csdn\.net/(answer|doc|column)/([a-zA-Z0-9_-]+)', url)
            if wenku_match:
                return wenku_match.group(2)
            # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            wenku_match = re.search(r'wenku\.csdn\.net/[^/]+/([a-zA-Z0-9_-]+)', url)
            if wenku_match:
                return wenku_match.group(1)

        raise Exception(f"æ— æ³•ä»URLä¸­æå–æ–‡ç« ID: {url}")

    def unlock_vip_article(self, article_id: str, retry_with_login: bool = True) -> bool:
        """
        è§£é”VIPæ–‡ç«  - è°ƒç”¨CSDNè§£é”API

        Args:
            article_id: æ–‡ç« ID
            retry_with_login: å½“é‡åˆ°401é”™è¯¯æ—¶æ˜¯å¦é‡æ–°ç™»å½•åé‡è¯•

        Returns:
            bool: æ˜¯å¦è§£é”æˆåŠŸ
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ”“ å¼€å§‹è§£é”VIPæ–‡ç« ")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“„ æ–‡ç« ID: {article_id}")

        # ç›´æ¥åŠ è½½cookiesæ–‡ä»¶ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°çš„æœ‰æ•ˆcookies
        try:
            with open('cookies.json', 'r', encoding='utf-8') as f:
                cookies_dict = json.load(f)

            logger.info(f"æˆåŠŸåŠ è½½cookiesæ–‡ä»¶ï¼Œå…±{len(cookies_dict)}ä¸ªcookies")
            logger.info(f"å…³é”®cookies - UserToken: {cookies_dict.get('UserToken', 'NOT_FOUND')[:20]}...")

            # åˆ›å»ºæ–°çš„sessionï¼Œç›´æ¥åŠ è½½cookies
            session = requests.Session()

            # è®¾ç½®cookiesåˆ°æ­£ç¡®çš„åŸŸ
            for name, value in cookies_dict.items():
                session.cookies.set(name, value, domain='.csdn.net')

            # è®¾ç½®å®Œæ•´çš„è¯·æ±‚å¤´ï¼ˆå¤åˆ»æˆåŠŸæµ‹è¯•è„šæœ¬çš„é…ç½®ï¼‰
            session.headers.update({
                'Accept': '*/*',
                'Content-Type': 'application/json; charset=UTF-8',
                'Origin': 'https://blog.csdn.net',
                'Referer': f'https://blog.csdn.net/article/details/{article_id}',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
                'X-Requested-With': 'XMLHttpRequest',
            })

            logger.info(f"Cookiesæ•°é‡: {len(session.cookies)}")
            logger.info(f"å…³é”®cookieså­˜åœ¨æ£€æŸ¥:")
            has_user_token = any(cookie.name == 'UserToken' for cookie in session.cookies)
            has_user_info = any(cookie.name == 'UserInfo' for cookie in session.cookies)
            logger.info(f"   UserToken: {has_user_token}, UserInfo: {has_user_info}")

            # ğŸ”‘ å‘é€è§£é”è¯·æ±‚
            unlock_url = "https://blog.csdn.net/phoenix/web/v1/vip-article-read"
            payload = {"articleId": int(article_id)}
            
            logger.info(f"è§£é”æ¥å£: {unlock_url}")
            logger.info(f"è¯·æ±‚æ•°æ®: {json.dumps(payload)}")
            logger.info(f"å‘é€è§£é”è¯·æ±‚...")
            
            response = session.post(unlock_url, json=payload, timeout=30, verify=False)
            
            logger.info(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            logger.info(f"å“åº”å†…å®¹: {response.text[:500]}")
            
            try:
                result = response.json()
                logger.info(f"ğŸ“¨ APIå“åº”: {json.dumps(result, ensure_ascii=False)}")
                
                if result.get('code') == 200:
                    logger.info(f"âœ… VIPæ–‡ç« è§£é”æˆåŠŸï¼")
                    logger.info(f"{'='*60}\n")
                    return True
                elif result.get('code') == 400:
                    # 400 é€šå¸¸è¡¨ç¤ºæ–‡ç« ä¸æ˜¯VIPæ–‡ç« ï¼Œæˆ–å·²è§£é”
                    logger.info(f"â„¹ï¸  æ–‡ç« å¯èƒ½ä¸æ˜¯VIPæ–‡ç« æˆ–å·²è§£é”")
                    logger.info(f"{'='*60}\n")
                    return True
                else:
                    logger.warning(f"âš ï¸  è§£é”å¤±è´¥: code={result.get('code')}, message={result.get('message')}")
                    logger.info(f"{'='*60}\n")
                    return False
                    
            except json.JSONDecodeError:
                logger.warning(f"è§£é”APIè¿”å›éJSONå“åº”: {response.text[:100]}")
                logger.info(f"{'='*60}\n")
                # æ— æ³•è§£æå“åº”ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç™»å½•
                if retry_with_login:
                    logger.info("å°è¯•ä½¿ç”¨å›é€€æ–¹æ³•...")
                    return self._unlock_vip_article_fallback(article_id, retry_with_login=False)
                else:
                    return False

        except Exception as e:
            logger.error(f"åŠ è½½cookieså¤±è´¥: {str(e)}")
            # å›é€€åˆ°åŸæ¥çš„æ–¹æ³•
            return self._unlock_vip_article_fallback(article_id, retry_with_login)

    def _unlock_vip_article_fallback(self, article_id: str, retry_with_login: bool = True) -> bool:
        """
        è§£é”VIPæ–‡ç« çš„å›é€€æ–¹æ³• - ä½¿ç”¨auth_serviceçš„session
        """
        logger.info(f"ğŸ”„ ä½¿ç”¨å›é€€æ–¹æ³•è§£é”VIPæ–‡ç« ")

        self.ensure_login()
        session = self.auth_service.get_session()

        # è§£é”æ¥å£URL
        unlock_url = "https://blog.csdn.net/phoenix/web/v1/vip-article-read"
        logger.info(f"è§£é”æ¥å£: {unlock_url}")

        # è¯·æ±‚å¤´
        session.headers.update({
            'Accept': '*/*',
            'Content-Type': 'application/json; charset=UTF-8',
            'Origin': 'https://blog.csdn.net',
            'Referer': f'https://blog.csdn.net/article/details/{article_id}',
            'X-Requested-With': 'XMLHttpRequest',
        })

        # è¯·æ±‚ä½“
        payload = {"articleId": int(article_id)}
        logger.info(f"è¯·æ±‚æ•°æ®: {json.dumps(payload)}")

        try:
            logger.info(f"å‘é€è§£é”è¯·æ±‚...")
            response = session.post(unlock_url, json=payload, timeout=30, verify=False)

            logger.info(f"å“åº”çŠ¶æ€ç : {response.status_code}")
            logger.info(f"å“åº”å†…å®¹: {response.text[:500]}")

            try:
                result = response.json()
                logger.info(f"è§£æåçš„å“åº”: {json.dumps(result, ensure_ascii=False, indent=2)}")

                if result.get('code') == 200:
                    logger.info(f"VIPæ–‡ç« è§£é”æˆåŠŸï¼")
                    logger.info(f"{'='*60}\n")
                    return True
                else:
                    logger.warning(f"è§£é”å¤±è´¥: code={result.get('code')}, message={result.get('message')}")
                    logger.info(f"{'='*60}\n")
                    # å³ä½¿å“åº”ä¸æ˜¯200ï¼Œä¹Ÿå°è¯•ç»§ç»­ä¸‹è½½
                    return True

            except json.JSONDecodeError:
                # å¦‚æœå“åº”ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå¯èƒ½æ˜¯ç©ºå“åº”
                logger.warning(f"è§£é”APIè¿”å›éJSONå“åº”: {response.text[:100]}")
                logger.warning("è¿™å¯èƒ½æ„å‘³ç€è´¦å·æ²¡æœ‰VIPæƒé™æˆ–cookieså·²è¿‡æœŸ")

                # å¼ºåˆ¶é‡æ–°ç™»å½•è·å–æ–°çš„VIPä¼šè¯
                logger.info("å°è¯•å¼ºåˆ¶é‡æ–°ç™»å½•è·å–æœ‰æ•ˆVIPä¼šè¯...")

                from app.core.config import settings
                username = settings.CSDN_USERNAME
                password = settings.CSDN_PASSWORD

                if username and password:
                    login_success = self.auth_service.login(username, password)
                    if login_success:
                        logger.info("é‡æ–°ç™»å½•æˆåŠŸï¼Œé‡è¯•è§£é”...")
                        # ä½¿ç”¨æ–°çš„cookiesé‡è¯•è§£é”
                        return self.unlock_vip_article(article_id, retry_with_login=False)
                    else:
                        logger.error("é‡æ–°ç™»å½•å¤±è´¥ï¼Œæ— æ³•è§£é”VIPæ–‡ç« ")
                        return False
                else:
                    logger.error("CSDNç™»å½•å‡­è¯æœªé…ç½®ï¼Œæ— æ³•é‡æ–°ç™»å½•")
                    return False

        except Exception as e:
            logger.error(f"å›é€€æ–¹æ³•ä¹Ÿå¤±è´¥: {str(e)}")
            return False

    def unlock_vip_wenku(self, wenku_id: str) -> bool:
        """
        è§£é”CSDNæ–‡åº“VIPæ–‡æ¡£

        Args:
            wenku_id: æ–‡æ¡£ID

        Returns:
            bool: æ˜¯å¦è§£é”æˆåŠŸ
        """
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ”“ å¼€å§‹è§£é”CSDNæ–‡åº“VIPæ–‡æ¡£")
        logger.info(f"{'='*60}")
        logger.info(f"ğŸ“„ æ–‡æ¡£ID: {wenku_id}")

        try:
            # CSDNæ–‡åº“çš„è§£é”æ¥å£å¯èƒ½ä¸åšå®¢ä¸åŒï¼Œè¿™é‡Œå°è¯•å‡ ç§å¯èƒ½çš„æ–¹å¼
            # æ–¹å¼1: å°è¯•é€šç”¨çš„VIPè§£é”æ¥å£
            unlock_urls = [
                "https://wenku.csdn.net/phoenix/web/v1/vip-article-read",
                "https://wenku.csdn.net/phoenix/web/v1/vip-wenku-read",
                "https://blog.csdn.net/phoenix/web/v1/vip-article-read"  # å›é€€åˆ°åšå®¢æ¥å£
            ]

            payload = {"articleId": wenku_id, "wenkuId": wenku_id}

            session = self.auth_service.get_session()

            for unlock_url in unlock_urls:
                try:
                    logger.info(f"å°è¯•è§£é”æ¥å£: {unlock_url}")

                    # è®¾ç½®è¯·æ±‚å¤´
                    session.headers.update({
                        'Accept': '*/*',
                        'Content-Type': 'application/json; charset=UTF-8',
                        'Origin': 'https://wenku.csdn.net',
                        'Referer': f'https://wenku.csdn.net/answer/{wenku_id}',
                        'X-Requested-With': 'XMLHttpRequest',
                    })

                    response = session.post(unlock_url, json=payload, timeout=30, verify=False)

                    logger.info(f"å“åº”çŠ¶æ€ç : {response.status_code}")
                    logger.info(f"å“åº”å†…å®¹: {response.text[:500]}")

                    if response.status_code == 200:
                        try:
                            result = response.json()
                            logger.info(f"ğŸ“¨ APIå“åº”: {json.dumps(result, ensure_ascii=False)}")

                            if result.get('code') == 200:
                                logger.info(f"âœ… CSDNæ–‡åº“VIPæ–‡æ¡£è§£é”æˆåŠŸï¼")
                                logger.info(f"{'='*60}\n")
                                return True
                            elif result.get('code') == 400:
                                logger.info(f"â„¹ï¸  æ–‡æ¡£å¯èƒ½ä¸æ˜¯VIPæ–‡æ¡£æˆ–å·²è§£é”")
                                logger.info(f"{'='*60}\n")
                                return True
                            else:
                                logger.warning(f"âš ï¸  è§£é”å¤±è´¥: code={result.get('code')}, message={result.get('message')}")

                        except json.JSONDecodeError:
                            logger.warning(f"è§£é”APIè¿”å›éJSONå“åº”: {response.text[:100]}")

                except Exception as e:
                    logger.warning(f"è§£é”æ¥å£ {unlock_url} å¤±è´¥: {str(e)}")
                    continue

            logger.info(f"{'='*60}\n")
            return False

        except Exception as e:
            logger.error(f"è§£é”CSDNæ–‡åº“VIPæ–‡æ¡£å¤±è´¥: {str(e)}")
            logger.info(f"{'='*60}\n")
            return False

    def is_vip_article_locked(self, html_content: str, url: str = "") -> bool:
        """
        æ£€æµ‹æ–‡ç« æ˜¯å¦ä¸ºVIPé”å®šçŠ¶æ€ï¼ˆé’ˆå¯¹å…·ä½“æ¥å£ä¼˜åŒ–ï¼‰

        å¯¹äºå¸¦cookiesè®¿é—®çš„wenkuæ¥å£ï¼Œé€šå¸¸ä¸ä¼šæœ‰é”å®šæ ‡è¯†ï¼Œ
        æ­¤æ–¹æ³•ä¸»è¦ç”¨äºæ—¥å¿—è®°å½•å’Œå…¼å®¹æ€§æ£€æµ‹

        Args:
            html_content: æ–‡ç« HTMLå†…å®¹
            url: æ–‡ç« URLï¼Œç”¨äºåŒºåˆ†åšå®¢å’Œæ–‡åº“

        Returns:
            bool: æ˜¯å¦ä¸ºVIPé”å®šçŠ¶æ€
        """
        if 'wenku.csdn.net' in url:
            # é’ˆå¯¹å…·ä½“çš„wenku/answeræ¥å£ï¼Œè½»é‡çº§æ£€æµ‹
            # å› ä¸ºå¸¦cookiesè®¿é—®é€šå¸¸å·²è§£é”ï¼Œåªéœ€è®°å½•å¼‚å¸¸çŠ¶æ€

            # å¿«é€Ÿæ–‡æœ¬æ£€æµ‹ï¼Œæ— éœ€å¤æ‚DOMè§£æ
            content_lower = html_content.lower()

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„VIPé”å®šæ ‡è¯†
            vip_indicators = [
                'å¼€é€šä¼šå‘˜æŸ¥çœ‹å®Œæ•´ç­”æ¡ˆ',
                'æœ€ä½0.3å…ƒ/å¤©',
                'é˜…è¯»å…¨æ–‡',
                'class="open-btn-wrap"',
                'data-vip="true"'
            ]

            for indicator in vip_indicators:
                if indicator.lower() in content_lower:
                    logger.info(f"æ£€æµ‹åˆ°å¯èƒ½çš„VIPæ ‡è¯†: {indicator}")
                    return True

            # å¯¹äºwenkuæ¥å£ï¼Œé»˜è®¤è®¤ä¸ºå·²è§£é”
            return False

        else:
            # CSDNåšå®¢çš„VIPé”å®šæ£€æµ‹ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            vip_lock_indicators = [
                'class="vip-mask"',
                'class="read-all-content-btn"',
                'vip-article-read',
                'data-vip="true"',
                'vip-lock',
                'vip-mask'
            ]

            content_lower = html_content.lower()

            for indicator in vip_lock_indicators:
                if indicator.lower() in content_lower:
                    logger.info(f"æ£€æµ‹åˆ°CSDNåšå®¢VIPé”å®šæ ‡å¿—: {indicator}")
                    return True

            return False

    def download_article(self, url: str) -> dict:
        """
        ä¸‹è½½CSDNæ–‡ç« HTML - æ”¯æŒVIPæ–‡ç« è§£é”æ£€æµ‹

        Args:
            url: æ–‡ç« URL

        Returns:
            dict: åŒ…å«urlã€titleã€htmlçš„å­—å…¸
        """
        self.ensure_login()

        # æå–æ–‡ç« ID
        try:
            article_id = self.extract_article_id(url)
        except Exception as e:
            logger.error(f"æå–æ–‡ç« IDå¤±è´¥: {str(e)}")
            article_id = None

        # æ·»åŠ å®Œæ•´çš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br, zstd',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Cache-Control': 'max-age=0',
            'Connection': 'keep-alive',
            'DNT': '1',
            'Referer': url,
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36',
            'sec-ch-ua': '"Google Chrome";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"'
        }

        def build_session() -> requests.Session:
            new_session = self.auth_service.get_session()
            new_session.headers.update(headers)
            return new_session

        def fetch_html(current_session: requests.Session) -> str:
            logger.info(f"æ­£åœ¨ä¸‹è½½æ–‡ç« é¡µé¢: {url}")
            response = current_session.get(url, timeout=30, verify=False)
            response.raise_for_status()
            return response.text

        session = build_session()
        unlock_success = False

        try:
            full_html = fetch_html(session)

            # æ£€æŸ¥æ˜¯å¦ä¸ºVIPé”å®šæ–‡ç« 
            # å¯¹äºå¸¦cookiesè®¿é—®ï¼Œæ­£å¸¸æƒ…å†µä¸‹ä¸åº”æœ‰é”å®šæ ‡è¯†
            # å¦‚æœæ£€æµ‹åˆ°é”å®šæ ‡è¯†ï¼Œå¯èƒ½æ„å‘³ç€cookieå·²å¤±æ•ˆ
            is_locked = self.is_vip_article_locked(full_html, url)
            if is_locked:
                logger.warning("âš ï¸  æ£€æµ‹åˆ°VIPé”å®šæ ‡è¯†ï¼Œå°è¯•æ‰§è¡Œè§£é”æµç¨‹")

                if article_id:
                    logger.info("ï¿½ è°ƒç”¨VIPè§£é”æ¥å£...")
                    unlock_success = self.unlock_vip_article(article_id)
                    if unlock_success:
                        logger.info("âœ… VIPè§£é”æˆåŠŸï¼Œåˆ·æ–°æ–‡ç« å†…å®¹")
                        session = build_session()
                        full_html = fetch_html(session)
                        is_locked = self.is_vip_article_locked(full_html, url)

                if is_locked and not unlock_success:
                    logger.info("ğŸ”„ å°è¯•é‡æ–°ç™»å½•è·å–æœ‰æ•ˆcookies...")
                    try:
                        if self._force_relogin():
                            logger.info("âœ… é‡æ–°ç™»å½•æˆåŠŸï¼Œåˆ·æ–°ä¼šè¯")
                            session = build_session()

                            if article_id:
                                unlock_success = self.unlock_vip_article(article_id)

                            full_html = fetch_html(session)
                            is_locked = self.is_vip_article_locked(full_html, url)

                            if is_locked:
                                logger.error("âŒ é‡æ–°ç™»å½•åä»æ£€æµ‹åˆ°VIPé”å®šï¼Œå¯èƒ½è´¦å·æ— æƒé™æˆ–é¡µé¢ç»“æ„å˜åŒ–")
                            else:
                                logger.info("âœ… é‡æ–°ç™»å½•åVIPé”å®šè§£é™¤")
                        else:
                            logger.error("âŒ é‡æ–°ç™»å½•å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰cookies")
                    except Exception as login_error:
                        logger.error(f"âŒ é‡æ–°ç™»å½•è¿‡ç¨‹å‡ºé”™: {str(login_error)}")
            else:
                logger.info("âœ… æœªæ£€æµ‹åˆ°VIPé”å®šï¼Œæ­£å¸¸å¤„ç†æ–‡æ¡£")

            # è§£æHTML
            soup = BeautifulSoup(full_html, 'html.parser')

            # æå–æ–‡ç« æ ‡é¢˜
            title = "æœªçŸ¥æ ‡é¢˜"
            title_selectors = [
                'h1.title-article',
                '.article-title',
                'h1[class*="title"]',
                'article h1'
            ]

            for selector in title_selectors:
                title_element = soup.select_one(selector)
                if title_element:
                    title = title_element.get_text(strip=True)
                    break

            # æå–æ–‡ç« å†…å®¹
            article_content = None

            # æ ¹æ®URLç±»å‹é€‰æ‹©ä¸åŒçš„å†…å®¹é€‰æ‹©å™¨
            if 'wenku.csdn.net' in url:
                # é’ˆå¯¹å…·ä½“çš„wenku/answeræ¥å£ä¼˜åŒ–å†…å®¹æå–
                # åŸºäºå·²çŸ¥çš„å…·ä½“æ¥å£ç»“æ„
                content_selectors = [
                    '.markdown_views',      # ä¸»è¦çš„markdownå†…å®¹åŒºåŸŸ
                    '.content-view',        # å†…å®¹è§†å›¾å®¹å™¨
                    '.answer_content',      # å›ç­”å†…å®¹åŒºåŸŸ
                    'div.markdown_views',   # å…·ä½“çš„markdownå®¹å™¨
                    '.content',             # é€šç”¨å†…å®¹åŒºåŸŸ
                    'article',              # æ–‡ç« å®¹å™¨
                ]
            else:
                # CSDNåšå®¢å†…å®¹é€‰æ‹©å™¨
                content_selectors = [
                    '#article_content',
                    '.article_content',
                    'article',
                    '.blog-content-box'
                ]

            for selector in content_selectors:
                content_element = soup.select_one(selector)
                if content_element:
                    article_content = str(content_element)
                    logger.info(f"âœ… æ‰¾åˆ°å†…å®¹åŒºåŸŸ: {selector}")

                    # é’ˆå¯¹wenkuçš„ç‰¹æ®Šå¤„ç†ï¼šç§»é™¤å¯èƒ½çš„é®ç›–å…ƒç´ 
                    if 'wenku.csdn.net' in url:
                        # æ¸…ç†å†…å®¹ä¸­çš„é®ç›–å…ƒç´ 
                        content_soup = BeautifulSoup(article_content, 'html.parser')

                        # ç§»é™¤"é˜…è¯»å…¨æ–‡"ç›¸å…³å…ƒç´ 
                        for overlay in content_soup.find_all(class_=['open', 'open-btn', 'open-btn-wrap']):
                            overlay.decompose()

                        # ç§»é™¤é«˜åº¦é™åˆ¶
                        for container in content_soup.find_all(class_=['cont', 'content-view']):
                            if 'first-show' in container.get('class', []):
                                container['class'].remove('first-show')
                            if container.get('style'):
                                container['style'] = re.sub(r'(max-)?height:\s*\d+px[^;]*;?', '', container['style'])

                        article_content = str(content_soup)

                    break

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ç« å†…å®¹ï¼Œè¿”å›æ•´ä¸ªé¡µé¢
            if not article_content:
                article_content = full_html

            return {
                "url": url,
                "title": title,
                "html": full_html,  # å®Œæ•´HTMLï¼ˆå¯èƒ½æ˜¯è§£é”åçš„ï¼‰
                "content": article_content,  # æ–‡ç« å†…å®¹éƒ¨åˆ†
                "is_vip_locked": is_locked and article_id and not unlock_success  # VIPé”å®šçŠ¶æ€
            }

        except requests.exceptions.Timeout:
            logger.error("âŒ è¯·æ±‚è¶…æ—¶")
            raise Exception("ä¸‹è½½æ–‡ç« å¤±è´¥: è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        except requests.exceptions.ConnectionError:
            logger.error("âŒ è¿æ¥å¤±è´¥")
            raise Exception("ä¸‹è½½æ–‡ç« å¤±è´¥: æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
        except requests.exceptions.HTTPError as e:
            logger.error(f"âŒ HTTPé”™è¯¯: {e.response.status_code}")
            raise Exception(f"ä¸‹è½½æ–‡ç« å¤±è´¥: HTTP {e.response.status_code}")
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}")
            raise Exception(f"ä¸‹è½½æ–‡ç« å¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"âŒ è§£ææ–‡ç« å¤±è´¥: {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            raise Exception(f"è§£ææ–‡ç« å¤±è´¥: {str(e)}")

    def extract_clean_content(self, html_content: str, title: str = "", url: str = "") -> str:
        """
        ä»å®Œæ•´HTMLä¸­æå–çº¯å‡€çš„æ–‡ç« å†…å®¹ï¼Œä¿æŒCSDNåŸç‰ˆæ ·å¼

        Args:
            html_content: å®Œæ•´çš„HTMLå†…å®¹
            title: æ–‡ç« æ ‡é¢˜
            url: æ–‡ç« URLï¼Œç”¨äºåŒºåˆ†åšå®¢å’Œæ–‡åº“

        Returns:
            str: æ¸…ç†åçš„HTMLå†…å®¹
        """
        soup = BeautifulSoup(html_content, 'html.parser')

        # æå–æ–‡ç« æ ‡é¢˜ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not title:
            if 'wenku.csdn.net' in url:
                # CSDNæ–‡åº“æ ‡é¢˜æå–
                title_elem = soup.find('h1', class_='title')
                if not title_elem:
                    title_elem = soup.find('h1')
                if not title_elem:
                    title_elem = soup.find('title')
            else:
                # CSDNåšå®¢æ ‡é¢˜æå–
                title_elem = soup.find('h1', class_='title-article')

            if title_elem:
                title = title_elem.get_text().strip()
                # æ¸…ç†titleæ ‡ç­¾ä¸­çš„åç¼€
                title = re.sub(r'-.*?CSDN.*?$', '', title).strip()
            else:
                title = "æ–‡ç« å†…å®¹"

        # æ ¹æ®URLç±»å‹é€‰æ‹©ä¸åŒçš„å†…å®¹åŒºåŸŸ
        if 'wenku.csdn.net' in url:
            # CSDNæ–‡åº“å†…å®¹æå–
            content_div = soup.find('div', class_='markdown_views')
            if not content_div:
                content_div = soup.find('div', class_='content-view')
            if not content_div:
                content_div = soup.find('div', class_='answer_content')
            if not content_div:
                content_div = soup.find('div', class_='content')
        else:
            # CSDNåšå®¢å†…å®¹æå–
            content_div = soup.find('div', {'id': 'content_views'})
            if not content_div:
                content_div = soup.find('div', {'class': 'article_content'})

        if not content_div:
            # å¦‚æœæ‰¾ä¸åˆ°å†…å®¹åŒºåŸŸï¼Œè¿”å›åŸå§‹HTML
            return html_content

        # æ¸…ç†ä¸éœ€è¦çš„å…ƒç´ 
        for element in content_div.find_all(['script', 'iframe', 'noscript']):
            element.decompose()

        # ç§»é™¤å¹¿å‘Šå’Œæ¨èç›¸å…³çš„div
        for element in content_div.find_all(['div', 'section'], class_=lambda x: x and any(
            keyword in str(x).lower() for keyword in ['ad', 'advert', 'recommend', 'relate', 'comment']
        )):
            element.decompose()

        # æå–CSDNåŸç‰ˆCSSæ ·å¼é“¾æ¥
        csdn_styles = []
        for link in soup.find_all('link', rel='stylesheet'):
            href = link.get('href', '')
            # åªä¿ç•™CSDNç›¸å…³çš„æ ·å¼æ–‡ä»¶
            if 'csdnimg.cn' in href or 'csdn.net' in href:
                if any(keyword in href for keyword in ['markdown_views', 'editerView', 'prism', 'highlight']):
                    csdn_styles.append(href)

        # è·å–æ¸…ç†åçš„å†…å®¹HTML
        clean_content_html = str(content_div)

        # æ„å»ºæ ·å¼é“¾æ¥
        style_links = '\n    '.join([f'<link rel="stylesheet" href="{url}">' for url in csdn_styles])

        # åˆ›å»ºHTMLé¡µé¢ï¼Œä¿æŒCSDNåŸç‰ˆæ ·å¼
        clean_html_template = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    {style_links}
    <style>
        body {{
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: #fff;
        }}
        #content_views {{
            font-size: 16px;
            line-height: 1.8;
        }}
    </style>
</head>
<body>
    <h1>{title}</h1>
    {clean_content_html}
</body>
</html>
"""
        return clean_html_template

    def save_article(self, url: str, output_dir: str = None) -> dict:
        """
        ä¸‹è½½CSDNæ–‡ç« å¹¶ä¿å­˜ä¸ºHTMLæ–‡ä»¶

        Args:
            url: æ–‡ç« URL
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸º downloads æ–‡ä»¶å¤¹

        Returns:
            dict: åŒ…å«file_pathã€file_sizeã€titleçš„å­—å…¸
        """
        # ä¸‹è½½æ–‡ç« 
        article_data = self.download_article(url)

        # æå–çº¯å‡€å†…å®¹
        clean_html = self.extract_clean_content(
            article_data['html'],
            article_data.get('title', 'æœªçŸ¥æ ‡é¢˜'),
            url
        )

        # ç¡®å®šè¾“å‡ºç›®å½•
        if not output_dir:
            output_dir = os.path.join(os.getcwd(), "downloads")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ ‡é¢˜ï¼‰
        title = article_data.get('title', 'æœªçŸ¥æ ‡é¢˜')
        # æ¸…ç†æ ‡é¢˜ä¸­çš„éæ³•å­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€å¸¸è§ç¬¦å·ï¼‰
        safe_title = re.sub(r'[<>:"/\\|?*]', '', title)  # ç§»é™¤Windowsæ–‡ä»¶åéæ³•å­—ç¬¦
        safe_title = safe_title.strip()

        # é™åˆ¶æ–‡ä»¶åé•¿åº¦
        if len(safe_title) > 100:
            safe_title = safe_title[:100]

        # å¦‚æœæ ‡é¢˜ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
        if not safe_title:
            safe_title = "æ–‡ç« "

        filename = f"{safe_title}.html"
        file_path = os.path.join(output_dir, filename)

        # ä¿å­˜HTMLæ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(clean_html)

        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)

        return {
            "file_path": file_path,
            "file_size": file_size,
            "title": title
        }

    def close(self):
        """å…³é—­æœåŠ¡"""
        self.auth_service.close()